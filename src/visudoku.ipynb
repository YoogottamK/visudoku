{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViSudoku\n",
    "\n",
    "This program can solve a sudoku puzzle if you show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# try block added to help in conversion to .py\n",
    "try:\n",
    "    %matplotlib inline\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from functools import reduce\n",
    "import subprocess\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the character that needs to be pressed \n",
    "#  for the webcam to capture a picture\n",
    "WEBCAM_CAPTURE_CHAR = 'c'\n",
    "\n",
    "# the number of characters(valid digits) in the puzzle\n",
    "N_CHARS = 9\n",
    "\n",
    "# The sudoku puzzle is resized to this\n",
    "#  please make this a multiple of N_CHARS above\n",
    "PUZZLE_SIZE_DIMEN = 450\n",
    "PUZZLE_SIZE = (PUZZLE_SIZE_DIMEN, PUZZLE_SIZE_DIMEN)\n",
    "EXTRACTED_DIGIT_DIMEN = 30\n",
    "EXTRACTED_DIGIT_SIZE = (EXTRACTED_DIGIT_DIMEN, EXTRACTED_DIGIT_DIMEN)\n",
    "\n",
    "# This will be the dimension of each box in the puzzle\n",
    "BOX_DIMEN = PUZZLE_SIZE_DIMEN / N_CHARS\n",
    "\n",
    "# PP means pre processing\n",
    "PP_BLUR_KERNEL_SIZE = (5, 5)\n",
    "\n",
    "# DX means digit extraction\n",
    "DX_DILATE_KERNEL_SIZE = (3, 3)\n",
    "DX_ERODE_KERNEL_SIZE = (5, 5)\n",
    "\n",
    "MODEL_LOCATION = \"../digit-recog/knn.model\"\n",
    "SOLVER_LOCATION = \"../sudoku-solver/sudoku-solver\"\n",
    "\n",
    "TEST_IMG_DIR = \"../test-images\"\n",
    "\n",
    "# colors are (b, g, r)\n",
    "COL_BLUE = (255, 0, 0)\n",
    "COL_GREEN = (0, 255, 0)\n",
    "COL_WHITE = (255, 255, 255)\n",
    "\n",
    "BOUNDARY_COLOR = COL_BLUE\n",
    "DX_BORDER_COLOR = COL_WHITE\n",
    "DX_BOX_COLOR = COL_GREEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the image\n",
    "\n",
    "In this section, we take the sudoku image which we want to solve\n",
    "\n",
    "We allow two methods for this: \n",
    "\n",
    "- Through an already captured image [change the path below]\n",
    "- Through the webcam, live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if path is valid, we take stored image else live input from webcam\n",
    "\n",
    "def get_sudoku_image(path):\n",
    "    img = cv.imread(path)\n",
    "    \n",
    "    if img is not None:\n",
    "        # Image will be loaded from disk\n",
    "        return img\n",
    "    else:\n",
    "        # Image will be taken from webcam\n",
    "        # ensure that proper drivers exist and the webcam works\n",
    "        # press `c` to capture the image\n",
    "        \n",
    "        WIN_NAME = 'live'\n",
    "\n",
    "        cap = cv.VideoCapture(0)\n",
    "        cv.namedWindow(WIN_NAME)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            cv.imshow(WIN_NAME, frame)\n",
    "\n",
    "            if cv.waitKey(1) & 0xFF == ord(WEBCAM_CAPTURE_CHAR):\n",
    "                img = frame\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv.destroyWindow(WIN_NAME)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic pre-processing\n",
    "\n",
    "It is recommended to convert our image to grayscale for processing. For most applications, color serves no major purpose. It is also recommended to blur the image so as to reduce noise in the image.\n",
    "\n",
    "In this section, we\n",
    "\n",
    "- Convert image to grayscale\n",
    "- Blur it\n",
    "- Binarize it [use only black/white]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: play around with kernel size for blurring and threshold\n",
    "\n",
    "def pre_process(img):\n",
    "    # convert to gray if not already gray\n",
    "    if len(img.shape) == 3:\n",
    "        proc = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        proc = img\n",
    "\n",
    "    proc = cv.GaussianBlur(proc, PP_BLUR_KERNEL_SIZE, 0)\n",
    "    proc = cv.adaptiveThreshold(proc, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    return proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the puzzle\n",
    "\n",
    "Now that we have the binarized image, we can extract the puzzle from the image.\n",
    "\n",
    "In this section, we\n",
    "\n",
    "- find all contours\n",
    "- find the largest contour [largest by area]\n",
    "- get it's corners\n",
    "\n",
    "#### What? Why? How?!:\n",
    "- It is assumed that if someone shows an image of a sudoku puzzle, it will be the largest object in the image, which is a reasonable assumption to make. So, we get all the boundaries and the one with the largest area will be our puzzle.\n",
    "- To extract the corners, we use the following logic [consider (0, 0) to be the top left corner]:\n",
    "    - Top Left corner will have minimum `x + y`\n",
    "    - Top Right corner will have maximum `x - y`\n",
    "    - Bottom Right corner will have maximum `x + y`\n",
    "    - Bottom Left corner will have minimum `x - y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_contour(contours):\n",
    "    return max(contours, key=lambda cnt: cv.contourArea(cnt))\n",
    "\n",
    "def get_contour_corners(contour):\n",
    "    sum_xy = [pt[0][0] + pt[0][1] for pt in contour]\n",
    "    diff_xy = [pt[0][0] - pt[0][1] for pt in contour]\n",
    "    \n",
    "    indices = [\n",
    "        np.argmin(sum_xy),\n",
    "        np.argmax(diff_xy),\n",
    "        np.argmax(sum_xy),\n",
    "        np.argmin(diff_xy)\n",
    "    ]\n",
    "    \n",
    "    return [contour[i][0] for i in indices]\n",
    "\n",
    "def get_corners(img):\n",
    "    # this weird syntax is used to make this compatible with both opencv v4 and v3\n",
    "    contours = cv.findContours(img, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "    puzzle_bound = get_largest_contour(contours)\n",
    "\n",
    "    return get_contour_corners(puzzle_bound)\n",
    "\n",
    "def extract_rect(img, corners, final_size=PUZZLE_SIZE):\n",
    "    # returns the euclidian distance between 2 points\n",
    "    dist = lambda p1, p2: np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "    tl, tr, br, bl = corners\n",
    "\n",
    "    # choose the side of final image as maximum of all sides\n",
    "    side = max([dist(tl, tr), dist(tr, bl), dist(br, bl), dist(bl, tl)])\n",
    "\n",
    "    # initial points / coords\n",
    "    src = np.array([tl, tr, br, bl], 'float32')\n",
    "    # final points / coords\n",
    "    dst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], 'float32')\n",
    "\n",
    "    # transform image to get just the puzzle\n",
    "    m = cv.getPerspectiveTransform(src, dst)\n",
    "    puzzle = cv.warpPerspective(img, m, (int(side), int(side)))\n",
    "    \n",
    "    # resize to final_size\n",
    "    puzzle = cv.resize(puzzle, final_size)\n",
    "\n",
    "    return puzzle\n",
    "\n",
    "\n",
    "def mark_boundary(img, corners):\n",
    "    \"\"\"\n",
    "    This is purely for visualisation purposes.\n",
    "    \n",
    "    This draws a box on the image with the specified corners\n",
    "    \"\"\"\n",
    "\n",
    "    tl, tr, br, bl = [tuple(x) for x in corners]\n",
    "    \n",
    "    cv.line(img, tl, tr, BOUNDARY_COLOR, 3)\n",
    "    cv.line(img, tr, br, BOUNDARY_COLOR, 3)\n",
    "    cv.line(img, br, bl, BOUNDARY_COLOR, 3)\n",
    "    cv.line(img, bl, tl, BOUNDARY_COLOR, 3)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract digits\n",
    "\n",
    "Now that we have the puzzle boundary, we need to extract each digit out of it. To do this, I have done the following:\n",
    "- dilate then erode then image: This ensures that all grid lines are connected\n",
    "- add a border to the image: This ensures that any part of the grid which might have been lost in trying to 'flatten' the image is restored\n",
    "- Get the grid lines using `cv.HoughLines`, and then, draw them again to make the grid lines prominent\n",
    "- erode then dilate: this removes any unnecessary small blobs [noise] from the image so they don't interfere in contour detection\n",
    "- Get 82 largest contours(by area). The largest one will be the whole puzzle. the other 81 will be the boxes inside which digits are present\n",
    " - To get them in the correct order, I check the center of the image, then approxiamate it. This approxiamation is required since the coordinated weren't perfect, so, some images came out of order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mostly_empty(img, thresh=0.1):\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    white = np.count_nonzero(img)\n",
    "    \n",
    "    return white / total < thresh\n",
    "\n",
    "\n",
    "def approx_center(center):\n",
    "    \"\"\"\n",
    "    Approxiamates the box's center to help\n",
    "        in determining the order in which\n",
    "        they originally came in the puzzle\n",
    "    \"\"\"\n",
    "    \n",
    "    half_box = BOX_DIMEN / 2\n",
    "    \n",
    "    # this is a list of ideal box centers in the puzzle\n",
    "    valid_centers = np.arange(half_box, PUZZLE_SIZE_DIMEN - half_box + 1, BOX_DIMEN)\n",
    "\n",
    "    cx, cy = center\n",
    "    \n",
    "    x = valid_centers[np.argmin(np.abs(valid_centers - cx))]\n",
    "    y = valid_centers[np.argmin(np.abs(valid_centers - cy))]\n",
    "    \n",
    "    return (x, y)\n",
    "        \n",
    "\n",
    "def get_digits(img):        \n",
    "    img = cv.dilate(img, np.ones(DX_DILATE_KERNEL_SIZE, np.uint8))\n",
    "    img = cv.erode(img, np.ones(DX_ERODE_KERNEL_SIZE, np.uint8))\n",
    "    img = cv.copyMakeBorder(img, 5, 5, 5, 5, cv.BORDER_CONSTANT, None, DX_BORDER_COLOR)\n",
    "    \n",
    "    # enables us to draw coloured lines\n",
    "    img_color = cv.cvtColor(img, cv.COLOR_GRAY2BGR)        \n",
    "    cp_img_color = img_color.copy()\n",
    "    gridless = img_color.copy()\n",
    "    \n",
    "    edges = cv.Canny(img, 50, 150, apertureSize=3)\n",
    "    lines = cv.HoughLines(edges, 1, np.pi/180, 150)\n",
    "    \n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        \n",
    "        a, b = np.cos(theta), np.sin(theta)\n",
    "        x0, y0 = a * rho, b * rho\n",
    "        \n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        \n",
    "        cv.line(img_color, (x1, y1), (x2, y2), (0, 255, 0), 3) \n",
    "        cv.line(gridless, (x1, y1), (x2, y2), (0, 0, 0), 5)\n",
    "    \n",
    "    boxes = cv.cvtColor(img_color, cv.COLOR_BGR2GRAY)\n",
    "    boxes = cv.erode(boxes, np.ones(DX_ERODE_KERNEL_SIZE, np.uint8))\n",
    "    boxes = cv.dilate(boxes, np.ones(DX_DILATE_KERNEL_SIZE, np.uint8))\n",
    "    \n",
    "    contours = cv.findContours(boxes, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    \n",
    "    contours = sorted(contours, reverse=True, key=cv.contourArea)[1:82]\n",
    "    \n",
    "    digits = []\n",
    "    cv.drawContours(cp_img_color, contours, -1, DX_BOX_COLOR, 3)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        corners = get_contour_corners(cnt)        \n",
    "        digit = extract_rect(gridless, corners, EXTRACTED_DIGIT_SIZE)\n",
    "        digit = cv.dilate(digit, np.ones(DX_DILATE_KERNEL_SIZE, np.uint8))\n",
    "\n",
    "        digit = cv.cvtColor(digit, cv.COLOR_BGR2GRAY)\n",
    "        _, digit = cv.threshold(digit, 75, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        center = approx_center(list(np.array(reduce(lambda x1, x2: [x1[0] + x2[0], x1[1] + x2[1]], corners)) / 4))\n",
    "\n",
    "        digits.append({ \"img\": digit, \"center\": center })\n",
    "        \n",
    "    return sorted(digits, key=lambda x: [x['center'][1], x['center'][0]]), cp_img_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "These functions do something trivial which was required multiple times in the script or a new name gives them better meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_key(wait_char):\n",
    "    while True:\n",
    "        if cv.waitKey(1) & 0xFF == ord(wait_char):\n",
    "            break\n",
    "\n",
    "\n",
    "def display_img(img, name='Image', wait_key=None):\n",
    "    # display an image and wait for keypress\n",
    "    cv.imshow(name, img)\n",
    "    \n",
    "    if wait_key is None:\n",
    "        cv.waitKey(0)\n",
    "    else:\n",
    "        wait_for_key(wait_key)\n",
    "\n",
    "\n",
    "def is_running():\n",
    "    return __name__ == '__main__' and '__file__' not in globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The trained model for digit recog\n",
    "\n",
    "The model is trained and stored as a pickle in `digit-recog/knn.model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_model():\n",
    "    model_pickle = open(MODEL_LOCATION, 'rb')\n",
    "    model = pickle.load(model_pickle)\n",
    "    model_pickle.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def classify_img(model, img):\n",
    "    return str(model.predict([img.flatten()])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The solver\n",
    "\n",
    "This is an old project (from class 10 or something)\n",
    "I didn't want to write it all over again, so I modified it a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(puzzle):\n",
    "    solver = subprocess.Popen([SOLVER_LOCATION], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    solver.stdin.write((puzzle + \"\\n\").encode())\n",
    "\n",
    "    out = solver.communicate()[0]\n",
    "    \n",
    "    ret_val = solver.returncode\n",
    "    \n",
    "    solver.stdin.close()\n",
    "    \n",
    "    solver.terminate()\n",
    "    \n",
    "    return out.decode(\"utf-8\"), ret_val == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO!!!\n",
    "\n",
    "Please ensure that you have run each and every code cell above this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy check to ensure that this segment runs only if we ran this from this file itself\n",
    "# and not for including it somewhere else\n",
    "\n",
    "def solve_visudoku(img_path=None, debug=False):\n",
    "    \n",
    "    img_stages = []\n",
    "    \n",
    "    # get the image\n",
    "    img = get_sudoku_image(img_path)\n",
    "    \n",
    "    img_stages.append({ \"label\": \"Input\", \"img\": img.copy() })\n",
    "    \n",
    "    if debug:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    # make a copy of the original image [used later]\n",
    "    copy = img\n",
    "\n",
    "    # pre-process image\n",
    "    img = pre_process(img)\n",
    "    \n",
    "    img_stages.append({ \"label\": \"Post Preprocessing\", \"img\": img.copy() })\n",
    "    \n",
    "    if debug:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    # extract corners of the puzzle\n",
    "    corners = get_corners(img)\n",
    "    # draw boundary on the image\n",
    "    marked = mark_boundary(copy, corners)\n",
    "    \n",
    "    img_stages.append({ \"label\": \"Boundaries marked\", \"img\": marked.copy() })\n",
    "\n",
    "    if debug:\n",
    "        plt.imshow(marked)\n",
    "        plt.show()\n",
    "    \n",
    "    puzzle = extract_rect(img, corners)\n",
    "    \n",
    "    img_stages.append({ \"label\": \"Extracted puzzle\", \"img\": puzzle.copy() })\n",
    "    \n",
    "    if debug:\n",
    "        plt.imshow(puzzle)\n",
    "        plt.show()\n",
    "    \n",
    "    digits, boxed_digits = get_digits(puzzle)\n",
    "    \n",
    "    img_stages.append({ \"label\": \"Boxed digits\", \"img\": boxed_digits.copy() })\n",
    "    \n",
    "    if debug:\n",
    "        plt.imshow(boxed_digits)\n",
    "        plt.show()\n",
    "    \n",
    "    model = get_model()\n",
    "    nums = []\n",
    "    \n",
    "    for dig in digits:\n",
    "        num = classify_img(model, dig['img'])\n",
    "        \n",
    "        if debug:\n",
    "            print(num)\n",
    "            plt.imshow(dig['img'], cmap='gray')\n",
    "            plt.show()\n",
    "        \n",
    "        nums.append(classify_img(model, dig['img']))\n",
    "        \n",
    "    solution, success = solve(' '.join(nums))\n",
    "    \n",
    "    return solution, success, img_stages, nums\n",
    "\n",
    "    \n",
    "if is_running():\n",
    "    for i in range(6):\n",
    "        img_path = f\"{TEST_IMG_DIR}/test{i}.jpg\"\n",
    "        \n",
    "        img = cv.imread(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        solution, success, img_stages, nums = solve_visudoku(img_path)\n",
    "        \n",
    "        if success:\n",
    "            print(solution)\n",
    "        else:\n",
    "            print(\"Oops, something went wrong!\")\n",
    "            print(\"It will soon be possible to correct this mistake!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
